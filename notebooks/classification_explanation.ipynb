{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": ""
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Description du Modèle de Classification d'Images\n",
    "\n",
    "Dans ce notebook, nous allons détailler un modèle de réseau de neurones convolutionnel (CNN) conçu pour la classification d'images. Le modèle est conçu pour distinguer deux classes : par exemple, \"Sain\" et \"Pneumonie\". Nous allons décrire l'architecture du modèle, les hyperparamètres utilisés, et les résultats d'évaluation.\n",
    "\n",
    "## Objectifs\n",
    "- Comprendre la structure du modèle CNN\n",
    "- Examiner les hyperparamètres choisis\n",
    "- Analyser les résultats obtenus après l'entraînement\n"
   ],
   "id": "523714bfbad12fb5"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Architecture du Modèle\n",
    "\n",
    "Le modèle utilisé dans ce projet est un réseau de neurones convolutionnel (CNN) construit avec `tensorflow.keras`. Il comporte plusieurs couches de convolution, de pooling et de dropout, suivies de couches entièrement connectées.\n",
    "\n",
    "Voici la structure détaillée du modèle :\n"
   ],
   "id": "f6bf59bef5016e8a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "def model_ia(train_dataset, val_dataset, test_dataset):\n",
    "    model = models.Sequential([\n",
    "        layers.InputLayer(input_shape=(150, 150, 1)),\n",
    "\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Dropout(0.25),\n",
    "\n",
    "        layers.Flatten(),\n",
    "\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "\n",
    "        layers.Dense(2, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    return model\n"
   ],
   "id": "b3f9eea0baea4283"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Description des Couches\n",
    "\n",
    "- **Input Layer** : Accepte des images de taille 150x150 pixels avec 1 canaux car seulement des couleurs de gris.\n",
    "- **Convolutional Layers** : Trois couches de convolution avec des tailles de filtre de 3x3. Le nombre de filtres augmente à chaque couche (32, 64, 128) pour capturer des caractéristiques de plus en plus complexes.\n",
    "- **Pooling Layers** : Chaque couche de convolution est suivie d'une couche de pooling (2x2) pour réduire la dimensionnalité et extraire les caractéristiques dominantes.\n",
    "- **Dropout Layers** : Les couches Dropout (0.25 et 0.5) sont ajoutées pour éviter le surapprentissage en désactivant aléatoirement une fraction des neurones.\n",
    "- **Dense Layers** : Une couche dense de 128 neurones avec activation ReLU, suivie d'une couche de sortie avec 2 neurones et activation Softmax pour la classification binaire.\n"
   ],
   "id": "2cc5d99c5cfeefe3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Hyperparamètres Utilisés\n",
    "\n",
    "Les hyperparamètres suivants ont été définis pour contrôler le comportement du modèle :\n",
    "\n",
    "- **`input_shape`** : `(150, 150, 1)` - La taille des images d'entrée.\n",
    "- **`filters`** : `32`, `64`, `128` - Nombre de filtres dans les couches de convolution.\n",
    "- **`kernel_size`** : `(3, 3)` - Taille des filtres de convolution.\n",
    "- **`pool_size`** : `(2, 2)` - Taille des fenêtres de pooling.\n",
    "- **`dropout_rate`** : `0.25` pour les couches après chaque convolution, `0.5` avant la dernière couche dense.\n",
    "- **`units`** : `128` - Nombre de neurones dans la couche dense avant la sortie.\n",
    "- **`activation`** : `relu` pour les couches intermédiaires, `softmax` pour la couche de sortie.\n",
    "- **`optimizer`** : `adam` - Algorithme d'optimisation utilisé pour l'entraînement.\n",
    "- **`loss`** : `categorical_crossentropy` - Fonction de perte pour la classification multiclasse.\n",
    "- **`epochs`** : `[10, 50]` - Nombre de fois que l'ensemble des données d'entraînement est parcouru pendant l'entraînement. Ici nous avons tester avec 2 valeurs différentes.\n"
   ],
   "id": "969d1eaccced93d2"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Entraînement du Modèle\n",
    "\n",
    "Le modèle est entraîné sur les données d'entraînement (`train_dataset`) et validé sur les données de validation (`val_dataset`). Le processus d'entraînement se déroule sur 10 et 50 époques.\n"
   ],
   "id": "5217e5ea1fe3b868"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "\n",
    "from src.data_handling import generate_labeled_data, create_dataset\n",
    "from src.model import model_ia\n",
    "from src.visualization import history_plot\n",
    "\n",
    "\n",
    "def main():\n",
    "    # Labeliser les données\n",
    "    data_dir = 'src/data/chest_Xray'\n",
    "\n",
    "    df = generate_labeled_data(data_dir)\n",
    "\n",
    "    output_csv_path = 'src/labeled/labeled_dataset.csv'\n",
    "    df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "    # Préparer les données\n",
    "    df = pd.read_csv('src/labeled/labeled_dataset.csv')\n",
    "\n",
    "    label_map = {'Healthy': 0, 'Pneumonia': 1}\n",
    "\n",
    "    train_df = df[df['type'] == 'train']\n",
    "    val_df = df[df['type'] == 'val']\n",
    "    test_df = df[df['type'] == 'test']\n",
    "\n",
    "    train_dataset = create_dataset(train_df, label_map)\n",
    "    val_dataset = create_dataset(val_df, label_map)\n",
    "    test_dataset = create_dataset(test_df, label_map)\n",
    "\n",
    "    # Entraîner le modèle\n",
    "    model, history, val_loss, val_acc = model_ia(train_dataset, val_dataset, test_dataset)\n",
    "\n",
    "    # Visualiser les résultats\n",
    "    history_plot(history)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ],
   "id": "b953c4d651cf9c1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "\n",
    "def history_plot(history):\n",
    "    # Summarize history for accuracy\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])\n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()\n",
    "\n",
    "    # Summarize history for loss\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['Train', 'Validation'], loc='upper left')\n",
    "    plt.show()"
   ],
   "id": "cd31dfc2f0bee62b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Graphique Importé\n",
    "\n",
    "Voici les deux graphiques importé depuis une capture d'écran.\n",
    "\n",
    "![Graphique avec 10 époques](assets/img/10epochs.png)\n",
    "![Graphique avec 50 époques](assets/img/50epochs.png)\n",
    "\n",
    "\n",
    "\n"
   ],
   "id": "5171a7d68d9ae4b0"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Conclusion\n",
    "\n",
    "Nous avons construit et entraîné un modèle CNN pour la classification d'images en deux classes. Les résultats de validation montrent que le modèle surapprend pour le moment.\n",
    "\n",
    "Pour des améliorations futures, nous pourrions envisager :\n",
    "- D'augmenter la taille des données d'entraînement pour améliorer la généralisation.\n",
    "- D'ajuster davantage les hyperparamètres, notamment le nombre de filtres et les taux de dropout.\n",
    "- D'utiliser des techniques d'augmentation de données pour augmenter la diversité des données d'entraînement.\n"
   ],
   "id": "af0b8bf15d7b261b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
